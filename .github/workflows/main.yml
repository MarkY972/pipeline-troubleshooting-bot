name: CI/CD Pipeline

on: [push, pull_request]

jobs:
  build: # This job simulates a build, test, (optional) deploy, and AI analysis pipeline
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        # If scripts/requirements.txt exists, install from it
        if [ -f scripts/requirements.txt ]; then pip install -r scripts/requirements.txt; fi

    - name: Run log parser script
      run: python scripts/log_parser.py # Default run (e.g. on successful builds or for general checks)

    - name: Simulate a failed step
      id: simulated_fail_step
      run: |
        echo "This is a simulated error message from a failed build or deployment step."
        echo "Error: Unable to connect to the deployment target."
        echo "Details: Connection timed out after 30 seconds."
        echo "{\"level\": \"error\", \"message\": \"Deployment failed due to timeout\", \"service\": \"deploy-script\"}" > simulated_error_log.txt
        # exit 1 # Uncomment to actually fail the step and see continue-on-error in action for AI analysis
      continue-on-error: true # Ensure subsequent steps run even if this one "fails"

    - name: Analyze Logs from Simulated Failed Step
      id: ai_analysis
      if: always() # always() ensures this runs even if previous steps fail (and continue-on-error is true)
      run: |
        echo "--- Analyzing logs from simulated failure ---"
        if [ -f simulated_error_log.txt ]; then
          python scripts/log_parser.py --log-file simulated_error_log.txt
        elif [ "${{ steps.simulated_fail_step.outcome }}" == "failure" ]; then
          # In a real scenario, you might try to capture actual stdout/stderr from steps.simulated_fail_step.outputs.stdout etc.
          # For now, we'll pass a generic message if the file isn't created but the step was meant to fail.
          python scripts/log_parser.py --log-string "Simulated failure occurred. Log content: ${{ steps.simulated_fail_step.outputs.stdout }}"
        else
          echo "No specific error log file found from simulated_fail_step, and step did not 'fail'."
          python scripts/log_parser.py --log-string "Simulated step completed (or no error simulated). No specific logs to analyze from it."
        fi
        # Store suggestion as an output (example) which could be used by a subsequent step.
        # The Python script currently prints the AI suggestion to stdout.
        # To capture it as a step output:
        # 1. Modify the Python script to print ONLY the suggestion to stdout at the very end,
        #    or print a specific marker line like "AI_SUGGESTION_START" then the suggestion then "AI_SUGGESTION_END".
        # 2. Capture it in the GHA step:
        #    suggestion_output=$(python scripts/log_parser.py --log-file simulated_error_log.txt)
        #    echo "suggestion=${suggestion_output}" >> $GITHUB_OUTPUT
        #
        # Then, a later step could use `steps.ai_analysis.outputs.suggestion`.

    # --- Conceptual Suggestion Delivery Steps ---
    # - name: Post AI Suggestion to PR
    #   if: github.event_name == 'pull_request' # Only run for PRs
    #   uses: peter-evans/create-or-update-comment@v3
    #   with:
    #     issue-number: ${{ github.event.pull_request.number }}
    #     body: |
    #       **ðŸ¤– AI Troubleshooting Assistant Suggests:**
    #
    #       ${{ steps.ai_analysis.outputs.suggestion }} # Assuming suggestion is set as output
    #   env:
    #     GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Needs pull-requests: write permission
    #
    # - name: Send Slack Notification with AI Suggestion
    #   if: always() && env.SLACK_BOT_TOKEN != '' # always() to run even on failure, if configured
    #   uses: slackapi/slack-github-action@v1.24.0
    #   with:
    #     channel-id: ${{ env.SLACK_CHANNEL_ID }} # e.g., C1234567890
    #     slack-message: "CI/CD Pipeline Alert on ${{ github.repository }}:\nJob: ${{ github.job }}\nStatus: ${{ job.status }}\n*AI Suggestion:*\n${{ steps.ai_analysis.outputs.suggestion }}"
    #   env:
    #     SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
    #     SLACK_CHANNEL_ID: ${{ secrets.SLACK_CHANNEL_ID }} # Secret for the channel ID

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0 # Specify a version for consistency

    - name: Terraform Init
      id: init
      run: terraform -chdir=./terraform init
      # Add AWS credentials here if you were to deploy
      # env:
      #   AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #   AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Terraform Validate
      id: validate
      run: terraform -chdir=./terraform validate

    - name: Terraform Plan
      id: plan
      run: terraform -chdir=./terraform plan -no-color
      # Add AWS credentials here if you were to deploy or run plan against actual state
      # env:
      #   AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #   AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      continue-on-error: true # If plan fails, we still want to try to parse logs

    # Placeholder for capturing Terraform plan output if needed for the AI
    # - name: Capture Terraform Plan Output
    #   if: steps.plan.outcome == 'failure' || steps.plan.outcome == 'success' # Or always capture
    #   run: |
    #     echo "Terraform plan output:"
    #     echo "${{ steps.plan.outputs.stdout }}" > terraform_plan.txt
    #     # The actual output is in steps.plan.outputs.stdout, but it can be very large.
    #     # For now, we'll rely on the job logs if a manual inspection is needed.
    #     # The AI would ideally get the direct output from a failed apply step.
